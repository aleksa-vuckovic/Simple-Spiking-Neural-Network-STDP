{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "import math\n",
    "# import tensorflow_datasets as tfds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m (ds_train, ds_test), ds_info \u001B[38;5;241m=\u001B[39m \u001B[43mtfds\u001B[49m\u001B[38;5;241m.\u001B[39mload(\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmnist\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      3\u001B[0m     split\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      4\u001B[0m     shuffle_files\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m      5\u001B[0m     as_supervised\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m      6\u001B[0m     with_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m      7\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tfds' is not defined"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Parameters\n",
    "image_train_time = 350\n",
    "\n",
    "min_frequency = 1\n",
    "max_frequency = 50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m<tokenize>:27\u001B[0;36m\u001B[0m\n\u001B[0;31m    return spike_trains\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def encode_image_to_spike_train(image: np.ndarray):\n",
    "    spike_trains = []\n",
    "\n",
    "    for x_position in range(image.shape[0]):\n",
    "        for y_position in range(image.shape[1]):\n",
    "\n",
    "            pixel_value = image[x_position][y_position]\n",
    "\n",
    "            spike_train = np.zeros(shape=(image_train_time,))\n",
    "\n",
    "            # Transfer pixel value to set frequency range(and some other stuff, which interp does...)\n",
    "            frequency = np.interp(pixel_value, [np.min(image),np.max(image)], [min_frequency,max_frequency])\n",
    "\n",
    "            spike_time_distance = math.ceil(image_train_time / frequency)\n",
    "            next_spike_time = spike_time_distance\n",
    "\n",
    "            if pixel_value > 0:\n",
    "                while next_spike_time < image_train_time + 1:\n",
    "                    # Add Spike to Spike Train\n",
    "                    spike_train[int(next_spike_time)] = 1\n",
    "\n",
    "                    # Calculate next spike\n",
    "                    next_spike_time += spike_time_distance\n",
    "\n",
    "            spike_trains.append(spike_train)\n",
    "\n",
    "    return spike_trains\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def receptive_field(image: np.ndarray):\n",
    "    image_size_x = image.shape[0]\n",
    "    image_size_y = image.shape[1]\n",
    "\n",
    "    weight1 =  0.625\n",
    "    weight2 =  0.125\n",
    "    weight3 = -0.125\n",
    "    weight4 = -.5\n",
    "\n",
    "    # Receptive Field Kernel\n",
    "    receptive_field = [\n",
    "        [weight4 ,weight3 , weight2 ,weight3 ,weight4],\n",
    "        [weight3 ,weight2 , weight1 ,weight2 ,weight3],\n",
    "        [ weight2 ,weight1 ,   1    ,weight1 ,weight2],\n",
    "        [weight3 ,weight2 , weight1 ,weight2 ,weight3],\n",
    "        [weight4 ,weight3 , weight2 ,weight3 ,weight4]]\n",
    "\n",
    "    convoluted_image = np.zeros(image.shape)\n",
    "\n",
    "    window = [-2,-1,0,1,2]\n",
    "    x_offset = 2\n",
    "    y_offset = 2\n",
    "\n",
    "    # Apply Convolution with Receptive Field Kernel\n",
    "    for x_image_index in range(image_size_x):\n",
    "        for y_image_index in range(image_size_y):\n",
    "            summation = 0\n",
    "            for x_kernel_index in window:\n",
    "                for y_kernel_index in window:\n",
    "                    if (x_image_index+x_kernel_index)>=0 and (x_image_index+x_kernel_index)<=image_size_x-1 and (y_image_index+y_kernel_index)>=0 and (y_image_index+y_kernel_index)<=image_size_y-1:\n",
    "                        summation = summation + (receptive_field[x_offset+x_kernel_index][y_offset+y_kernel_index] * image[x_image_index+x_kernel_index][y_image_index+y_kernel_index]) / 255\n",
    "            convoluted_image[x_image_index][y_image_index] = summation\n",
    "    return convoluted_image\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.00266146,  0.00268965,  0.00094861, ...,  0.00525109,\n         0.00685579,  0.00365209],\n       [ 0.00576661,  0.00673441,  0.00488531, ...,  0.00563804,\n         0.00761841,  0.00603703],\n       [ 0.0059476 ,  0.00551406,  0.00396932, ...,  0.00244514,\n         0.00512528,  0.00603047],\n       ...,\n       [ 0.00589134,  0.00912306,  0.0065426 , ..., -0.00061937,\n         0.00399403,  0.00444065],\n       [ 0.0034775 ,  0.00631703,  0.00562848, ...,  0.00118717,\n         0.00463192,  0.00629945],\n       [ 0.00011449,  0.00114841,  0.00202604, ...,  0.00144466,\n         0.00423957,  0.00531666]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = np.random.rand(255,255)\n",
    "receptive_field(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f745ac6c5e51780c970d708e9a81e93505a8519a7fdc5ddf40a62ff87c8f2d95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}